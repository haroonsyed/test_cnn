{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer\n",
    "class ConvLayer:\n",
    "    def __init__(self, input_shape, kernel_shape):\n",
    "        input_rows, input_cols, input_channels = input_shape\n",
    "        filter_count, kernel_rows, kernel_cols = kernel_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.kernel_shape = kernel_shape\n",
    "        self.output_shape = (\n",
    "            input_rows - kernel_rows + 1,\n",
    "            input_cols - kernel_cols + 1,\n",
    "            filter_count,\n",
    "        )\n",
    "        self.prev_input = np.zeros(input_shape)\n",
    "        self.prev_output = np.zeros(self.output_shape)\n",
    "\n",
    "        # Initialize filters with he initalization\n",
    "        n_in = input_channels * kernel_rows * kernel_cols\n",
    "        self.filters = np.random.randn(\n",
    "            filter_count, input_channels, kernel_rows, kernel_cols\n",
    "        ) * np.sqrt(2 / n_in)\n",
    "        self.biases = np.zeros((filter_count, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    def __init__(self, input_shape):\n",
    "        input_rows, input_cols, input_channels = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = (\n",
    "            input_rows // 2 + input_rows % 2,\n",
    "            input_cols // 2 + input_cols % 2,\n",
    "            input_channels,\n",
    "        )\n",
    "        self.prev_input = np.zeros(input_shape)\n",
    "        self.prev_output = np.zeros(self.output_shape)\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "    def __init__(self, input_shape, num_classifications):\n",
    "        input_rows, input_cols, input_channels = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classifications = num_classifications\n",
    "\n",
    "        # There will be no hidden layers\n",
    "        # To stay consistent with the rust implementation, each column represents an observation\n",
    "        # This means that for the weights, the number of rows is equal to the number of features\n",
    "\n",
    "        # Initialize weights with he initalization\n",
    "        self.weights = np.random.randn(\n",
    "            num_classifications, input_channels * input_rows * input_cols\n",
    "        ) * np.sqrt(2 / (input_channels * input_rows * input_cols))\n",
    "        self.biases = np.zeros((num_classifications, 1))\n",
    "\n",
    "    def flatten(self, input):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_shape, num_classifications):\n",
    "        input_rows, input_cols, input_channels = input_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classifications = num_classifications\n",
    "        self.layers = []\n",
    "\n",
    "    def forward(self, input):\n",
    "        layer_input = input\n",
    "        for layer in self.layers:\n",
    "            layer_input = layer.forward(layer_input)\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        layer_error = output_error\n",
    "        for layer in reversed(self.layers):\n",
    "            layer_error = layer.backward(layer_error, learning_rate)\n",
    "\n",
    "    def train(self, input, labels, learning_rate):\n",
    "        pass\n",
    "\n",
    "    def predict(self, input):\n",
    "        pass\n",
    "\n",
    "    def add_conv_layer(self, kernel_shape):\n",
    "        prev_shape = (\n",
    "            self.input_shape if len(self.layers) == 0 else self.layers[-1].output_shape\n",
    "        )\n",
    "        self.layers.append(ConvLayer(prev_shape, kernel_shape))\n",
    "\n",
    "    def add_max_pool_layer(self):\n",
    "        prev_shape = (\n",
    "            self.input_shape if len(self.layers) == 0 else self.layers[-1].output_shape\n",
    "        )\n",
    "        self.layers.append(MaxPoolLayer(prev_shape))\n",
    "\n",
    "    def add_fully_connected_layer(self):\n",
    "        prev_shape = (\n",
    "            self.input_shape if len(self.layers) == 0 else self.layers[-1].output_shape\n",
    "        )\n",
    "        self.layers.append(FullyConnectedLayer(prev_shape, self.num_classifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets load the dataset cifar-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Load as numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(30, 30, 32)\n",
      "(28, 28, 64)\n",
      "(14, 14, 64)\n"
     ]
    }
   ],
   "source": [
    "# CNN with 2 CNN layers, 32x3x3 filters, 64x3x3 filters, max pool layer, fully connected layer\n",
    "# 10 classifications\n",
    "# 10 epochs\n",
    "# 32 batch size\n",
    "\n",
    "num_classifications = 10\n",
    "input_width = 32\n",
    "input_height = 32\n",
    "input_channels = 3\n",
    "\n",
    "cnn = CNN((input_width, input_height, input_channels), num_classifications)\n",
    "cnn.add_conv_layer((32, 3, 3))\n",
    "cnn.add_conv_layer((64, 3, 3))\n",
    "cnn.add_max_pool_layer()\n",
    "cnn.add_fully_connected_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1389162046.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "learning_rate = 0.01  # For now we will use stochastic gradient descent, not adam\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the data\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        # Get the batch\n",
    "        x_batch = x_train[i : i + batch_size]\n",
    "        y_batch = y_train[i : i + batch_size]\n",
    "\n",
    "        # Train the model\n",
    "        cnn.train(x_batch, y_batch, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
